# Codex MCP Integration Guide

How to integrate Codex MCP into the ToT system within the Claude Code CLI environment

## ğŸ¯ Core Concepts

```yaml
Execution Environment:
  - Runs inside Claude Code CLI
  - No API calls
  - Codex MCP invocation via Task tool

Thought Generation Method:
  - Claude thoughts: Self-generated (immediate)
  - Codex thoughts: Task tool â†’ MCP call
```

---

## ğŸ“‹ Codex MCP Call Interface

### 1. Basic Call Structure

```python
# Calling Codex MCP from Claude Code
Task(
    subagent_type="general-purpose",
    description="ToT Codex thought generation",
    prompt=f"""
{task_context}

**Task**: {task.get_proposal_prompt(x, current_thought)}

**Requirements**:
1. Generate {n_codex_thoughts} distinct solution approaches
2. Output format (JSON):
{{
  "thoughts": [
    {{
      "id": "codex_1",
      "text": "solution approach description",
      "reasoning": "why this approach"
    }},
    ...
  ]
}}

**Important**:
- í•œêµ­ì–´ë¡œ ì‘ë‹µ
- ê¸°ìˆ ì  ê¹Šì´ ìš°ì„ 
- ì•Œê³ ë¦¬ì¦˜/ì„±ëŠ¥ ìµœì í™” ê´€ì 
"""
)
```

### 2. Prompt Structure

```yaml
Codex MCP Prompt Composition:
  1. Context Provision:
     - Problem description (x)
     - Current thought state (current_thought)
     - Task type (Debug/Refactor/Design)

  2. Generation Instructions:
     - Number of thoughts to generate
     - Output format (JSON)
     - Quality criteria

  3. Constraints:
     - Korean response
     - Technical depth
     - Specific perspective (algorithm/performance)
```

---

## ğŸ”„ Integration Workflow

### Codex MCP Integration in BFS

```python
def generate_thoughts_hybrid(task, x, current_thoughts, args):
    """
    Hybrid thought generation: Claude self + Codex MCP

    Args:
        task: Task object (DebugTask/RefactorTask/DesignTask)
        x: Initial problem description
        current_thoughts: List of thoughts at current level
        args: ToT parameters (n_generate_sample, ratio, etc.)

    Returns:
        List[Thought]: Integrated list of Claude + Codex thoughts
    """

    # 1. Calculate ratio
    claude_ratio, codex_ratio = parse_ratio(args.ratio)  # e.g., "5:5" â†’ 0.5, 0.5
    n_total = args.n_generate_sample
    n_claude = int(n_total * claude_ratio)
    n_codex = int(n_total * codex_ratio)

    all_thoughts = []

    # 2. Generate Claude thoughts (self)
    for i in range(n_claude):
        prompt = task.get_proposal_prompt(x, current_thoughts[-1] if current_thoughts else "")

        # Claude Code self-response (immediate generation)
        claude_response = f"""
[Claude ì‚¬ê³  {i+1}]

{generate_claude_thought(prompt)}
"""

        thought = Thought(
            id=f"claude_{len(all_thoughts)}",
            text=extract_thought_text(claude_response),
            model="claude",
            depth=len(current_thoughts)
        )
        all_thoughts.append(thought)

    # 3. Generate Codex thoughts (MCP call)
    if n_codex > 0:
        codex_thoughts = call_codex_mcp(
            task=task,
            x=x,
            current_thought=current_thoughts[-1] if current_thoughts else "",
            n_thoughts=n_codex,
            depth=len(current_thoughts)
        )
        all_thoughts.extend(codex_thoughts)

    return all_thoughts


def call_codex_mcp(task, x, current_thought, n_thoughts, depth):
    """
    Thought generation via Codex MCP

    In actual implementation, uses Task tool:
    - subagent_type: "general-purpose"
    - prompt: Structured thought generation request
    """

    # Construct prompt for Task tool call
    task_context = f"""
# ToT Thought Generation Request

## Problem Context
{x}

## Current Progress
{current_thought if current_thought else "Starting fresh"}

## Task Type
{task.__class__.__name__}

## Current Depth
Level {depth + 1}
"""

    generation_prompt = task.get_proposal_prompt(x, current_thought)

    codex_prompt = f"""
{task_context}

{generation_prompt}

**Generate {n_thoughts} distinct solution approaches.**

**Output Format** (strict JSON):
```json
{{
  "thoughts": [
    {{
      "id": "codex_1",
      "text": "ì²« ë²ˆì§¸ í•´ê²° ë°©ì•ˆ ì„¤ëª…",
      "reasoning": "ì´ ë°©ì•ˆì„ ì„ íƒí•œ ì´ìœ "
    }},
    {{
      "id": "codex_2",
      "text": "ë‘ ë²ˆì§¸ í•´ê²° ë°©ì•ˆ ì„¤ëª…",
      "reasoning": "ì´ ë°©ì•ˆì„ ì„ íƒí•œ ì´ìœ "
    }}
  ]
}}
```

**Requirements**:
- í•œêµ­ì–´ë¡œ ì‘ì„±
- ê¸°ìˆ ì  ê¹Šì´ ìš°ì„ 
- ì•Œê³ ë¦¬ì¦˜/ì„±ëŠ¥ ìµœì í™” ê´€ì 
- ê° ì‚¬ê³ ëŠ” ëª…í™•íˆ êµ¬ë¶„ë˜ì–´ì•¼ í•¨
"""

    # In actual execution:
    # Task(subagent_type="general-purpose",
    #      description="ToT Codex thought generation",
    #      prompt=codex_prompt)
    # is called in this format

    # Parse response
    codex_response = """
    ì—¬ê¸°ì— Task toolì˜ ì‹¤ì œ ì‘ë‹µì´ ë“¤ì–´ì˜´
    JSON í˜•íƒœë¡œ íŒŒì‹± ê°€ëŠ¥í•´ì•¼ í•¨
    """

    return parse_codex_response(codex_response, depth)


def parse_codex_response(response, depth):
    """
    Convert Codex MCP response to Thought object list
    """
    thoughts = []

    try:
        # Attempt JSON parsing
        import json
        data = json.loads(extract_json(response))

        for item in data.get("thoughts", []):
            thought = Thought(
                id=item["id"],
                text=item["text"],
                model="codex",
                depth=depth,
                metadata={
                    "reasoning": item.get("reasoning", "")
                }
            )
            thoughts.append(thought)

    except Exception as e:
        # Fallback to text parsing if JSON parsing fails
        thoughts = parse_text_fallback(response, depth)

    return thoughts
```

---

## ğŸ¯ Task Type-Specific Codex Prompts

### DebugTask - Codex Call

```python
def get_codex_debug_prompt(x, current_thought):
    return f"""
# Bug Debugging - Technical Analysis

## Problem
{x}

## Current Analysis
{current_thought}

**Generate 2 technical cause hypotheses:**

Focus on:
- Memory management issues
- Algorithm complexity
- Race conditions
- System-level bottlenecks

Output JSON:
{{
  "thoughts": [
    {{
      "id": "codex_1",
      "text": "ê¸°ìˆ ì  ì›ì¸ ë¶„ì„ 1",
      "reasoning": "ê·¼ê±°"
    }},
    {{
      "id": "codex_2",
      "text": "ê¸°ìˆ ì  ì›ì¸ ë¶„ì„ 2",
      "reasoning": "ê·¼ê±°"
    }}
  ]
}}
"""
```

### RefactorTask - Codex Call

```python
def get_codex_refactor_prompt(x, current_thought):
    return f"""
# Code Refactoring - Technical Optimization

## Code/System
{x}

## Current Strategy
{current_thought}

**Generate 2 technical optimization strategies:**

Focus on:
- Algorithm optimization (O(nÂ²) â†’ O(n log n))
- Data structure improvements
- Design pattern applications
- Performance bottlenecks

Output JSON:
{{
  "thoughts": [
    {{
      "id": "codex_1",
      "text": "ìµœì í™” ì „ëµ 1",
      "reasoning": "ê¸°ìˆ ì  ê·¼ê±°"
    }},
    {{
      "id": "codex_2",
      "text": "ìµœì í™” ì „ëµ 2",
      "reasoning": "ê¸°ìˆ ì  ê·¼ê±°"
    }}
  ]
}}
"""
```

### DesignTask - Codex Call

```python
def get_codex_design_prompt(x, current_thought):
    return f"""
# System Design - Technical Architecture

## Requirements
{x}

## Current Design Direction
{current_thought}

**Generate 2 innovative architectural patterns:**

Focus on:
- Scalability (horizontal/vertical)
- Performance characteristics
- Advanced design patterns
- System optimization

Output JSON:
{{
  "thoughts": [
    {{
      "id": "codex_1",
      "text": "ì•„í‚¤í…ì²˜ íŒ¨í„´ 1",
      "reasoning": "ê¸°ìˆ ì  ì¥ì "
    }},
    {{
      "id": "codex_2",
      "text": "ì•„í‚¤í…ì²˜ íŒ¨í„´ 2",
      "reasoning": "ê¸°ìˆ ì  ì¥ì "
    }}
  ]
}}
"""
```

---

## ğŸ” Codex MCP Integration in Evaluation

### Cross-Evaluation Implementation

```python
def evaluate_thoughts_hybrid(task, x, thoughts, args):
    """
    Hybrid evaluation: Claude + Codex cross-evaluation

    - Claude-generated thoughts â†’ Evaluated by Codex
    - Codex-generated thoughts â†’ Evaluated by Claude
    - Self-generated thoughts â†’ Self-evaluation
    """

    evaluations = {}

    for thought in thoughts:
        if thought.model == "claude":
            # Claude thought â†’ Codex evaluation
            codex_scores = call_codex_evaluation(task, x, thought, args.n_evaluate_sample)
            claude_scores = evaluate_self(task, x, thought, args.n_evaluate_sample)

            # Weighted average (Cross-evaluation has higher reliability)
            final_score = (
                sum(codex_scores) / len(codex_scores) * 0.6 +
                sum(claude_scores) / len(claude_scores) * 0.4
            )

        elif thought.model == "codex":
            # Codex thought â†’ Claude evaluation
            claude_scores = evaluate_self(task, x, thought, args.n_evaluate_sample)
            # Skip Codex self-evaluation (MCP call cost)

            final_score = sum(claude_scores) / len(claude_scores)

        evaluations[thought.id] = {
            "score": final_score,
            "confidence": calculate_confidence(thought),
            "breakdown": {
                "feasibility": score_feasibility(thought),
                "impact": score_impact(thought),
                "risk": score_risk(thought),
                "complexity": score_complexity(thought)
            }
        }

    return evaluations


def call_codex_evaluation(task, x, thought, n_evaluate):
    """
    Thought evaluation via Codex MCP
    """

    evaluation_prompt = f"""
# Thought Evaluation Request

## Original Problem
{x}

## Thought to Evaluate
{thought.text}
(Generated by: {thought.model})

## Task
Evaluate this solution approach on 4 criteria:

1. **Feasibility** (1-10): êµ¬í˜„ ê°€ëŠ¥ì„±
2. **Impact** (1-10): ë¬¸ì œ í•´ê²° íš¨ê³¼
3. **Risk** (1-10): ìœ„í—˜ë„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)
4. **Complexity** (1-10): êµ¬í˜„ ë³µì¡ë„ (ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ)

**Perform {n_evaluate} independent evaluations.**

**Output Format** (JSON):
```json
{{
  "evaluations": [
    {{
      "feasibility": 8,
      "impact": 9,
      "risk": 3,
      "complexity": 5,
      "overall": 8.2,
      "reasoning": "í‰ê°€ ê·¼ê±°"
    }},
    ...
  ]
}}
```

**Technical perspective required.**
"""

    # Task tool call
    # codex_response = Task(...)

    # Parse response
    scores = parse_evaluation_response(codex_response)
    return [eval["overall"] for eval in scores["evaluations"]]
```

---

## âš™ï¸ Execution Examples

### Complete BFS Execution Flow

```python
def run_tot_bfs_hybrid(problem, task_type="debug", ratio="5:5"):
    """
    Hybrid ToT BFS execution

    Example:
        run_tot_bfs_hybrid(
            problem="ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°œìƒ",
            task_type="debug",
            ratio="5:5"
        )
    """

    # 1. Create Task
    task = TaskFactory.create(task_type)

    # 2. Set parameters
    args = ToTArgs(
        n_generate_sample=5,    # Total 5 thoughts
        n_evaluate_sample=3,    # Each evaluated 3 times
        n_select_sample=3,      # Select top 3
        ratio=ratio,            # Claude:Codex = 5:5 â†’ 2-3 each
        max_depth=3
    )

    # 3. Run BFS
    print("=== ToT BFS ì‹œì‘ ===\n")

    current_thoughts = []

    for depth in range(args.max_depth):
        print(f"--- Level {depth + 1} ---")

        # Generate thoughts (Claude self + Codex MCP)
        new_thoughts = generate_thoughts_hybrid(
            task, problem, current_thoughts, args
        )

        print(f"ìƒì„±ëœ ì‚¬ê³ : {len(new_thoughts)}ê°œ")
        for t in new_thoughts:
            print(f"  [{t.model}] {t.id}: {t.text[:50]}...")

        # Evaluate (Hybrid cross-evaluation)
        evaluations = evaluate_thoughts_hybrid(
            task, problem, new_thoughts, args
        )

        print(f"\ní‰ê°€ ê²°ê³¼:")
        for t_id, eval_data in sorted(
            evaluations.items(),
            key=lambda x: x[1]["score"],
            reverse=True
        ):
            print(f"  {t_id}: {eval_data['score']:.1f} (ì‹ ë¢°ë„: {eval_data['confidence']:.0%})")

        # Select (Greedy with diversity)
        selected = select_thoughts_hybrid(
            new_thoughts, evaluations, args.n_select_sample
        )

        print(f"\nì„ íƒëœ ì‚¬ê³ : {len(selected)}ê°œ")
        for t in selected:
            score = evaluations[t.id]["score"]
            print(f"  [{t.model}] {t.id}: {score:.1f}")

        # Early termination check
        best_score = max(evaluations[t.id]["score"] for t in selected)
        if best_score >= 9.0:
            print(f"\nğŸ¯ ì¡°ê¸° ì¢…ë£Œ: ìµœê³  ì ìˆ˜ {best_score:.1f} ë‹¬ì„±")
            current_thoughts = selected
            break

        current_thoughts = selected
        print()

    # 4. Return optimal path
    best_thought = max(
        current_thoughts,
        key=lambda t: evaluations[t.id]["score"]
    )

    print("=== ìµœì  í•´ë‹µ ===")
    print(f"ëª¨ë¸: {best_thought.model}")
    print(f"ì ìˆ˜: {evaluations[best_thought.id]['score']:.1f}")
    print(f"ë‚´ìš©:\n{best_thought.text}")

    return best_thought
```

---

## ğŸ› ï¸ Utility Functions

### JSON Extraction and Parsing

```python
def extract_json(response):
    """
    Extract JSON block from response
    """
    import re

    # Find ```json ... ``` block
    json_match = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
    if json_match:
        return json_match.group(1)

    # Directly find { ... }
    json_match = re.search(r'\{.*\}', response, re.DOTALL)
    if json_match:
        return json_match.group(0)

    raise ValueError("JSON not found in response")


def parse_text_fallback(response, depth):
    """
    Text parsing fallback when JSON parsing fails
    """
    thoughts = []

    # Parse "1. ...\n2. ..." format
    import re
    matches = re.findall(r'(\d+)\.\s*([^\n]+)', response)

    for i, (num, text) in enumerate(matches):
        thought = Thought(
            id=f"codex_{i}",
            text=text.strip(),
            model="codex",
            depth=depth
        )
        thoughts.append(thought)

    return thoughts
```

---

## ğŸ“Š Performance Optimization

### Parallel Processing

```python
def generate_thoughts_parallel(task, x, current_thoughts, args):
    """
    Process Claude self-generation and Codex MCP calls in parallel
    """

    import concurrent.futures

    claude_ratio, codex_ratio = parse_ratio(args.ratio)
    n_total = args.n_generate_sample
    n_claude = int(n_total * claude_ratio)
    n_codex = int(n_total * codex_ratio)

    all_thoughts = []

    # Parallel execution
    with concurrent.futures.ThreadPoolExecutor(max_workers=2) as executor:
        # Claude generation (async)
        claude_future = executor.submit(
            generate_claude_thoughts, task, x, current_thoughts, n_claude
        )

        # Codex MCP call (async)
        codex_future = executor.submit(
            call_codex_mcp, task, x,
            current_thoughts[-1] if current_thoughts else "",
            n_codex, len(current_thoughts)
        )

        # Collect results
        all_thoughts.extend(claude_future.result())
        all_thoughts.extend(codex_future.result())

    return all_thoughts
```

### Caching

```python
# Codex MCP response caching
codex_cache = {}

def call_codex_mcp_cached(task, x, current_thought, n_thoughts, depth):
    """
    Return cached response for identical requests
    """
    cache_key = f"{task.__class__.__name__}:{x[:50]}:{depth}:{n_thoughts}"

    if cache_key in codex_cache:
        print(f"[Cache Hit] {cache_key}")
        return codex_cache[cache_key]

    result = call_codex_mcp(task, x, current_thought, n_thoughts, depth)
    codex_cache[cache_key] = result

    return result
```

---

## ğŸ¯ Practical Usage Examples

### Debugging Scenario

```bash
# Command
/tot debug -r 6:4 "ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°œìƒ"

# Execution flow:
# Level 1:
#   - [Claude] 3 thoughts (immediate generation)
#   - [Codex] 2 thoughts (MCP call)
#   - Hybrid evaluation
#   - Select top 3

# Level 2:
#   - From each of the selected 3
#   - [Claude] 2 + [Codex] 1
#   - Evaluate and select

# Level 3:
#   - Final verification
#   - Return optimal solution
```

### Actual Execution Log

```
=== ToT BFS ì‹œì‘ ===

--- Level 1: ì›ì¸ ë¶„ì„ ---
ìƒì„±ëœ ì‚¬ê³ : 5ê°œ
  [claude] claude_0: ìºì‹œ ë©”ëª¨ë¦¬ ë¯¸í•´ì œë¡œ ì¸í•œ ëˆ„ìˆ˜...
  [claude] claude_1: ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë“±ë¡ í›„ ë¯¸ì œê±°...
  [claude] claude_2: ì „ì—­ ë³€ìˆ˜ì— ëŒ€ìš©ëŸ‰ ë°ì´í„° ì €ì¥...
  [codex] codex_0: setInterval/setTimeout ë¯¸ì •ë¦¬... (MCP)
  [codex] codex_1: Closure ìˆœí™˜ ì°¸ì¡°... (MCP)

í‰ê°€ ê²°ê³¼:
  codex_0: 9.1 (ì‹ ë¢°ë„: 92%)
  claude_0: 8.5 (ì‹ ë¢°ë„: 88%)
  codex_1: 7.9 (ì‹ ë¢°ë„: 85%)
  claude_1: 7.5 (ì‹ ë¢°ë„: 83%)
  claude_2: 6.2 (ì‹ ë¢°ë„: 78%)

ì„ íƒëœ ì‚¬ê³ : 3ê°œ
  [codex] codex_0: 9.1
  [claude] claude_0: 8.5
  [codex] codex_1: 7.9

--- Level 2: ê²€ì¦ ë°©ë²• ---
...
```

---

## ğŸ“ Summary

**Core of Codex MCP Integration:**

1. **Use Task tool**: MCP integration without API calls
2. **Structured prompts**: Enforce JSON response format
3. **Parallel processing**: Simultaneous execution of Claude self + Codex MCP
4. **Cross-evaluation**: Ensure objectivity through mutual evaluation
5. **Caching**: Prevent duplicate MCP calls

**Advantages:**
- No API costs
- Optimized for Claude Code CLI environment
- Maximize hybrid synergy
- Transparent execution process

**Considerations:**
- Codex MCP responses must be JSON parsable
- Consider Task tool call time
- Error handling (fallback when MCP fails)

---

## ğŸ›¡ï¸ Error Handling & Fallback System

### 1. Codex MCP Availability Check

```python
def check_codex_mcp_availability():
    """
    Check if Codex MCP is available and responsive

    Returns:
        bool: True if Codex MCP is available
    """
    try:
        # Simple ping test with 5s timeout
        test_response = Task(
            subagent_type="general-purpose",
            description="Codex MCP health check",
            prompt='Return JSON: {"status": "OK"}',
            timeout=5000
        )

        import json
        data = json.loads(extract_json(test_response))

        return data.get("status") == "OK"

    except Exception as e:
        print(f"[Codex MCP] Connection failed: {e}")
        return False


def initialize_tot_mode(args):
    """
    Determine execution mode based on Codex MCP availability

    Returns:
        (mode, codex_available):
            - mode: "claude" | "codex" | "hybrid"
            - codex_available: bool | None
    """
    # User explicitly specified mode
    if args.mode == "claude":
        print("âœ… Claude ì „ìš© ëª¨ë“œ (ì‚¬ìš©ì ì§€ì •)")
        return "claude", None

    elif args.mode == "codex":
        print("âœ… Codex ì „ìš© ëª¨ë“œ (ì‚¬ìš©ì ì§€ì •)")
        codex_ok = check_codex_mcp_availability()

        if not codex_ok:
            print("âŒ ì˜¤ë¥˜: Codex MCP ì—°ê²° ë¶ˆê°€")
            print("   â†’ Claude ì „ìš© ëª¨ë“œë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤")
            return "claude", False

        return "codex", True

    # Hybrid mode (default) - auto-detect
    else:
        codex_ok = check_codex_mcp_availability()

        if codex_ok:
            print("âœ… Hybrid ëª¨ë“œ - Codex MCP ì—°ê²°ë¨")
            print(f"   Claude {args.ratio.split(':')[0]} + Codex {args.ratio.split(':')[1]}")
            return "hybrid", True
        else:
            print("âš ï¸  Hybrid ëª¨ë“œ ìš”ì²­ â†’ Codex MCP ì‘ë‹µ ì—†ìŒ")
            print("   â†’ Claude ì „ìš© ëª¨ë“œë¡œ ìë™ ì „í™˜")
            print("   (5ê°œ ìƒê° ëª¨ë‘ Claudeë¡œ ìƒì„±)")
            return "claude", False
```

### 2. Resilient Codex MCP Call with Retry

```python
def call_codex_mcp_with_retry(task, x, current_thought, n_thoughts, depth):
    """
    Call Codex MCP with automatic retry and fallback

    Returns:
        (thoughts, source):
            - thoughts: List[Thought]
            - source: "codex" | "claude_fallback"
    """
    max_retries = 2
    retry_delay = 5  # seconds

    for attempt in range(max_retries):
        try:
            print(f"  ğŸ”„ Codex MCP í˜¸ì¶œ ì¤‘... (ì‹œë„ {attempt + 1}/{max_retries})")

            # Construct Codex prompt
            codex_prompt = construct_codex_prompt(
                task=task,
                x=x,
                current_thought=current_thought,
                n_thoughts=n_thoughts
            )

            # Call Codex MCP via Task tool (30s timeout)
            codex_response = Task(
                subagent_type="general-purpose",
                description="ToT Codex thought generation",
                prompt=codex_prompt,
                timeout=30000
            )

            # Parse JSON response
            thoughts = parse_codex_response(codex_response, depth)

            if len(thoughts) == 0:
                raise ValueError("Codex returned empty thoughts")

            print(f"  âœ… Codex ì‚¬ê³  {len(thoughts)}ê°œ ìƒì„± ì™„ë£Œ")
            return thoughts, "codex"

        except TimeoutError:
            print(f"  â±ï¸  íƒ€ì„ì•„ì›ƒ (30ì´ˆ ì´ˆê³¼)")
            if attempt < max_retries - 1:
                print(f"  ğŸ”„ {retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(retry_delay)
                continue

        except json.JSONDecodeError as e:
            print(f"  âš ï¸  JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            if attempt < max_retries - 1:
                print(f"  ğŸ”„ {retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(retry_delay)
                continue

        except Exception as e:
            print(f"  âŒ Codex MCP ì˜¤ë¥˜: {e}")
            if attempt < max_retries - 1:
                print(f"  ğŸ”„ {retry_delay}ì´ˆ í›„ ì¬ì‹œë„...")
                time.sleep(retry_delay)
                continue

    # All retries failed â†’ Fallback to Claude
    print(f"  âš ï¸  ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ â†’ Claudeë¡œ ëŒ€ì²´ ìƒì„± ({n_thoughts}ê°œ)")

    claude_thoughts = generate_claude_thoughts(
        task=task,
        x=x,
        current_thought=current_thought,
        n_thoughts=n_thoughts,
        depth=depth
    )

    # Mark as fallback
    for thought in claude_thoughts:
        thought.metadata["fallback"] = True
        thought.metadata["intended_source"] = "codex"

    return claude_thoughts, "claude_fallback"
```

### 3. Hybrid Generation with Automatic Fallback

```python
def generate_thoughts_hybrid_resilient(task, x, current_thoughts, args):
    """
    Hybrid thought generation with automatic fallback

    Features:
    - Claude thoughts always succeed (immediate generation)
    - Codex thoughts have retry + fallback to Claude
    - User is notified of any failures
    """
    claude_ratio, codex_ratio = parse_ratio(args.ratio)
    n_total = args.n_generate_sample
    n_claude = int(n_total * claude_ratio)
    n_codex = int(n_total * codex_ratio)

    all_thoughts = []

    # 1. Generate Claude thoughts (always succeeds)
    print(f"ğŸ”„ Claude ì‚¬ê³  ìƒì„± ì¤‘... ({n_claude}ê°œ)")

    claude_thoughts = generate_claude_thoughts(
        task=task,
        x=x,
        current_thoughts=current_thoughts,
        n_thoughts=n_claude,
        depth=len(current_thoughts)
    )

    all_thoughts.extend(claude_thoughts)
    print(f"  âœ… Claude ì‚¬ê³  {len(claude_thoughts)}ê°œ ìƒì„± ì™„ë£Œ")

    # 2. Generate Codex thoughts (with fallback)
    if n_codex > 0:
        codex_thoughts, source = call_codex_mcp_with_retry(
            task=task,
            x=x,
            current_thought=current_thoughts[-1].text if current_thoughts else "",
            n_thoughts=n_codex,
            depth=len(current_thoughts)
        )

        all_thoughts.extend(codex_thoughts)

        if source == "claude_fallback":
            print(f"  â„¹ï¸  ì°¸ê³ : Codex ëŒ€ì‹  Claudeë¡œ ìƒì„±ë¨ ({n_codex}ê°œ)")

    return all_thoughts
```

### 4. User Feedback During Execution

```markdown
# Example Output - Successful Connection

ğŸŒ³ Tree of Thought - BFS (Hybrid Mode)

âœ… Hybrid ëª¨ë“œ - Codex MCP ì—°ê²°ë¨
   Claude 3 + Codex 2 (ratio 3:2)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ Level 1: ì›ì¸ ë¶„ì„

ğŸ”„ Claude ì‚¬ê³  ìƒì„± ì¤‘... (3ê°œ)
  âœ… Claude ì‚¬ê³  3ê°œ ìƒì„± ì™„ë£Œ

ğŸ”„ Codex MCP í˜¸ì¶œ ì¤‘... (ì‹œë„ 1/2)
  âœ… Codex ì‚¬ê³  2ê°œ ìƒì„± ì™„ë£Œ

ì´ 5ê°œ ì‚¬ê³  ìƒì„±:
  1. [Claude] ìºì‹œ ë©”ëª¨ë¦¬ ë¯¸í•´ì œ
  2. [Claude] ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë¯¸ì œê±°
  3. [Claude] ì „ì—­ ë³€ìˆ˜ ëŒ€ìš©ëŸ‰ ë°ì´í„°
  4. [Codex] setInterval/setTimeout ë¯¸ì •ë¦¬ â­
  5. [Codex] Closure ìˆœí™˜ ì°¸ì¡°
```

```markdown
# Example Output - Connection Failed (Fallback)

ğŸŒ³ Tree of Thought - BFS (Hybrid Mode)

âš ï¸  Hybrid ëª¨ë“œ ìš”ì²­ â†’ Codex MCP ì‘ë‹µ ì—†ìŒ
   â†’ Claude ì „ìš© ëª¨ë“œë¡œ ìë™ ì „í™˜
   (5ê°œ ìƒê° ëª¨ë‘ Claudeë¡œ ìƒì„±)

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“ Level 1: ì›ì¸ ë¶„ì„

ğŸ”„ Claude ì‚¬ê³  ìƒì„± ì¤‘... (5ê°œ)
  âœ… Claude ì‚¬ê³  5ê°œ ìƒì„± ì™„ë£Œ

ì´ 5ê°œ ì‚¬ê³  ìƒì„± (ëª¨ë‘ Claude):
  1. [Claude] ìºì‹œ ë©”ëª¨ë¦¬ ë¯¸í•´ì œ
  2. [Claude] ì´ë²¤íŠ¸ ë¦¬ìŠ¤ë„ˆ ë¯¸ì œê±°
  3. [Claude] ì „ì—­ ë³€ìˆ˜ ëŒ€ìš©ëŸ‰ ë°ì´í„°
  4. [Claude] setInterval/setTimeout ë¯¸ì •ë¦¬
  5. [Claude] Closure ìˆœí™˜ ì°¸ì¡°
```

```markdown
# Example Output - Partial Failure (Retry Success)

ğŸ“ Level 1: ì›ì¸ ë¶„ì„

ğŸ”„ Claude ì‚¬ê³  ìƒì„± ì¤‘... (3ê°œ)
  âœ… Claude ì‚¬ê³  3ê°œ ìƒì„± ì™„ë£Œ

ğŸ”„ Codex MCP í˜¸ì¶œ ì¤‘... (ì‹œë„ 1/2)
  â±ï¸  íƒ€ì„ì•„ì›ƒ (30ì´ˆ ì´ˆê³¼)
  ğŸ”„ 5ì´ˆ í›„ ì¬ì‹œë„...

ğŸ”„ Codex MCP í˜¸ì¶œ ì¤‘... (ì‹œë„ 2/2)
  âœ… Codex ì‚¬ê³  2ê°œ ìƒì„± ì™„ë£Œ

ì´ 5ê°œ ì‚¬ê³  ìƒì„±:
  [... normal output continues ...]
```

```markdown
# Example Output - Complete Failure (Full Fallback)

ğŸ“ Level 2: ê²€ì¦ ë°©ë²•

ğŸ”„ Claude ì‚¬ê³  ìƒì„± ì¤‘... (3ê°œ)
  âœ… Claude ì‚¬ê³  3ê°œ ìƒì„± ì™„ë£Œ

ğŸ”„ Codex MCP í˜¸ì¶œ ì¤‘... (ì‹œë„ 1/2)
  âŒ Codex MCP ì˜¤ë¥˜: Connection refused
  ğŸ”„ 5ì´ˆ í›„ ì¬ì‹œë„...

ğŸ”„ Codex MCP í˜¸ì¶œ ì¤‘... (ì‹œë„ 2/2)
  âŒ Codex MCP ì˜¤ë¥˜: Connection refused
  âš ï¸  ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ â†’ Claudeë¡œ ëŒ€ì²´ ìƒì„± (2ê°œ)

ì´ 5ê°œ ì‚¬ê³  ìƒì„±:
  1. [Claude] ì½”ë“œ ê²€ìƒ‰ ë°©ë²•
  2. [Claude] ë¡œê·¸ ë¶„ì„
  3. [Claude] í”„ë¡œíŒŒì¼ëŸ¬ ì‚¬ìš©
  4. [Claude] ë©”ëª¨ë¦¬ ë¤í”„ ë¶„ì„ (Codex ëŒ€ì²´)
  5. [Claude] ëŸ°íƒ€ì„ ëª¨ë‹ˆí„°ë§ (Codex ëŒ€ì²´)

â„¹ï¸  ì°¸ê³ : Codex ëŒ€ì‹  Claudeë¡œ ìƒì„±ë¨ (2ê°œ)
```

### 5. Summary

**Key Features of Fallback System:**

1. **Transparent Status**: User always knows connection state
2. **Automatic Recovery**: 2 retries with 5s delays
3. **Graceful Degradation**: Falls back to Claude without stopping
4. **Clear Feedback**: Emoji indicators (âœ…/âš ï¸/âŒ) for visual clarity
5. **No Data Loss**: Execution continues regardless of Codex status

**Error Scenarios Handled:**

- âœ… Initial connection check failure â†’ Auto-switch to Claude mode
- âœ… Timeout during generation â†’ Retry + fallback
- âœ… JSON parsing error â†’ Retry + fallback
- âœ… Network error â†’ Retry + fallback
- âœ… Empty response â†’ Retry + fallback

**User Experience:**

- **Best case**: Full Hybrid mode (1.5-2 min)
- **Fallback case**: Claude-only mode (~30s) - Still works perfectly
- **No manual intervention needed**: System handles all errors

---

*ToT system based on Claude Code CLI + Codex MCP with robust error handling*
